{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1d8d4f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='grade3', context='notebook', ticks=True, grid=False) \n",
    "# setting the style of the notebook to be monokai theme  \n",
    "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
    "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ce88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\train.csv', 'C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images\\\\Mild'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of images in the dataset\n",
    "train = []\n",
    "label = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b02a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir returns the list of files in the folder, in this case image class names\n",
    "for i in os.listdir('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images'):\n",
    "  train_class = os.listdir(os.path.join('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images', i))\n",
    "  for j in train_class:\n",
    "    img = os.path.join('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images', i, j)\n",
    "    train.append(img)\n",
    "    label.append(i)\n",
    "\n",
    "print('Number of train images : {} \\n'.format(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955898b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 5 images for each class in the dataset\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize = (20, 20))\n",
    "count = 0\n",
    "for i in os.listdir('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images'):\n",
    "  # get the list of images in a given class\n",
    "  train_class = os.listdir(os.path.join('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images',i))\n",
    "  for j in range(5):\n",
    "    img = os.path.join('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images', i, train_class[j])\n",
    "    img = PIL.Image.open(img)\n",
    "    axs[count][j].title.set_text(i)\n",
    "    axs[count][j].imshow(img)  \n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd65937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of images in each class in the training dataset\n",
    "\n",
    "No_images_per_class = []\n",
    "Class_name = []\n",
    "for i in os.listdir('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images'):\n",
    "  train_class = os.listdir(os.path.join('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\DR_project\\\\dataset\\\\archive\\\\colored_images', i))\n",
    "  No_images_per_class.append(len(train_class))\n",
    "  Class_name.append(i)\n",
    "  print('Number of images in {} = {} \\n'.format(i, len(train_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaba9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_df = pd.DataFrame({'Image': train,'Labels': label})\n",
    "retina_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data and split it into training and testing\n",
    "retina_df = shuffle(retina_df)\n",
    "train, test = train_test_split(retina_df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create run-time augmentation on training and test dataset\n",
    "# For training datagenerator, we add normalization, shear angle, zooming range and horizontal flip\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        shear_range = 0.2,\n",
    "        validation_split = 0.15)\n",
    "\n",
    "# For test datagenerator, we only normalize the data.\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)# Creating datagenerator for training, validation and test dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20efbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(X, filter, stage):\n",
    "  \n",
    "  # Convolutional_block\n",
    "  X_copy = X\n",
    "\n",
    "  f1 , f2, f3 = filter\n",
    "    \n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = MaxPool2D((2,2))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
    "\n",
    "\n",
    "  # Short path\n",
    "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
    "  X_copy = MaxPool2D((2,2))(X_copy)\n",
    "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  # Identity Block 1\n",
    "  X_copy = X\n",
    "\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  # Identity Block 2\n",
    "  X_copy = X\n",
    "\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resnet18(input_shape=(256, 256, 3), num_classes=5):\n",
    "    input_shape = (256,256,3)\n",
    "    #Input tensor shape\n",
    "    X_input = Input(input_shape)\n",
    "    #Zero-padding\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    # 1 - stage\n",
    "    X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
    "\n",
    "    # 2- stage\n",
    "    X = res_block(X, filter= [64,64,256], stage= 2)\n",
    "    # 3- stage\n",
    "    X = res_block(X, filter= [128,128,512], stage= 3)\n",
    "    # 4- stage\n",
    "    X = res_block(X, filter= [256,256,1024], stage= 4)\n",
    "    # # 5- stage\n",
    "    X = res_block(X, filter= [512,512,2048], stage= 5)\n",
    "\n",
    "    #Average Poolin\n",
    "    X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n",
    "\n",
    "\n",
    "    #Final layer\n",
    "\n",
    "\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    X = Dense(5, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "\n",
    "    model = Model( inputs= X_input, outputs = X, name = 'Resnet18')\n",
    "    return model\n",
    "\n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97475d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the hybrid model of CNN and LSTM\n",
    "def create_cnn_lstm_model(input_shape, num_classes):\n",
    "    cnn_model = resnet18(input_shape, num_classes)\n",
    "\n",
    "    # Extract CNN features\n",
    "    cnn_features = cnn_model.get_layer('Averagea_Pooling').output\n",
    "    cnn_features = Flatten()(cnn_features)\n",
    "\n",
    "    # Reshape features for LSTM\n",
    "    lstm_input = Reshape((1, -1))(cnn_features)\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm_output = LSTM(128)(lstm_input)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc_output = Dense(num_classes, activation='softmax', name='Dense_final')(lstm_output)\n",
    "\n",
    "    # Combined model\n",
    "    hybrid_model = Model(inputs=cnn_model.input, outputs=fc_output, name='HybridModel')\n",
    "    return hybrid_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the hybrid model\n",
    "hybrid_model = create_cnn_lstm_model(input_shape=(256, 256, 3), num_classes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cbd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, BatchNormalization, LSTM, ZeroPadding2D, Add, Activation, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587217f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "\n",
    "#save the best model with lower validation lossmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1de123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = hybrid_model.fit(train_generator, steps_per_epoch = train_generator.n // 32, epochs = 18, validation_data= validation_generator, validation_steps= validation_generator.n // 32, callbacks=[checkpointer , earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cbeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss','val_loss'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.load_weights(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268603e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "evaluate = hybrid_model.evaluate(test_generator, steps = test_generator.n // 32, verbose =1)\n",
    "\n",
    "print('Accuracy Test : {}'.format(evaluate[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87193284",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: 'Mild', 1: 'Moderate', 2: 'No_DR', 3:'Proliferate_DR', 4: 'Severe'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf48de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading images and their predictions \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import cv2\n",
    "\n",
    "prediction = []\n",
    "original = []\n",
    "image = []\n",
    "count = 0\n",
    "\n",
    "for item in range(len(test)):\n",
    "  #code to open the image\n",
    "  img= PIL.Image.open(test['Image'].tolist()[item])\n",
    "  #resizing the image to (256,256)\n",
    "  img = img.resize((256,256))\n",
    "  #appending image to the image list\n",
    "  image.append(img)\n",
    "  #converting image to array\n",
    "  img = np.asarray(img, dtype= np.float32)\n",
    "  #normalizing the image\n",
    "  img = img / 255\n",
    "  #reshaping the image in to a 4D array\n",
    "  img = img.reshape(-1,256,256,3)\n",
    "  #making prediction of the model\n",
    "  predict = hybrid_model.predict(img)\n",
    "  #getting the index corresponding to the highest value in the prediction\n",
    "  predict = np.argmax(predict)\n",
    "  #appending the predicted class to the list\n",
    "  prediction.append(labels[predict])\n",
    "  #appending original class to the list\n",
    "  original.append(test['Labels'].tolist()[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ff334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the test accuracy \n",
    "score = accuracy_score(original,prediction)\n",
    "print(\"Test Accuracy : {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29871c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the results\n",
    "import random\n",
    "fig=plt.figure(figsize = (100,100))\n",
    "for i in range(20):\n",
    "    j = random.randint(0,len(image))\n",
    "    fig.add_subplot(20, 1, i+1)\n",
    "    plt.xlabel(\"Prediction: \" + prediction[j] +\"   Original: \" + original[j])\n",
    "    plt.imshow(image[j])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895541f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_images_per_class\n",
    "Class_name\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(No_images_per_class, labels = Class_name, autopct = '%1.1f%%')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      featurewise_center=False,\n",
    "      samplewise_center=False,\n",
    "      featurewise_std_normalization=False,\n",
    "      samplewise_std_normalization=False,\n",
    "      zca_whitening=False,\n",
    "      zca_epsilon=1e-06,\n",
    "      rotation_range=0,\n",
    "      width_shift_range=0.0,\n",
    "      height_shift_range=0.0,\n",
    "      brightness_range=None,\n",
    "      shear_range=0.0,\n",
    "      zoom_range=0.0,\n",
    "      channel_shift_range=0.0,\n",
    "      fill_mode=\"nearest\",\n",
    "      cval=0.0,\n",
    "      horizontal_flip=False,\n",
    "      vertical_flip=False,\n",
    "      rescale=None,\n",
    "      preprocessing_function=None,\n",
    "      data_format=None,\n",
    "      validation_split=0.3,\n",
    "      dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62058c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the classification report\n",
    "print(classification_report(np.asarray(original), np.asarray(prediction)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc168e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plt.figure(figsize = (20,20))\n",
    "cm = confusion_matrix(np.asarray(original), np.asarray(prediction))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, ax = ax)\n",
    "\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Original')\n",
    "ax.set_title('Confusion_matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming you have a list of labels, for example:\n",
    "label1 = label  # Replace this with your actual labels\n",
    "\n",
    "# Convert string labels to integer indices\n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(label1))}\n",
    "label_indices = [class_mapping[label] for label in label1]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(label1))\n",
    "y_test = to_categorical(label_indices, num_classes=num_classes)\n",
    "\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hybrid_model.predict(test_generator)  # X_test should contain your test data\n",
    "y_true = np.argmax(y_test, axis=1)  # y_test should contain true labels in one-hot encoded format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_true is your true labels and y_pred is your predicted probabilities or class predictions\n",
    "# If y_pred is probabilities, convert it to class predictions\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ensure that y_true and y_pred have the same length\n",
    "y_true = y_true[:len(y_pred_classes)]\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55964fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and store the history\n",
    "history = hybrid_model.fit(train_generator, steps_per_epoch=train_generator.n // 32, epochs=18,\n",
    "                    validation_data=validation_generator, validation_steps=validation_generator.n // 32,\n",
    "                    callbacks=[checkpointer, earlystopping])\n",
    "\n",
    "# Access training and validation losses from the history object\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# Print or plot the losses\n",
    "print(\"Training Losses:\", training_loss)\n",
    "print(\"Validation Losses:\", validation_loss)\n",
    "\n",
    "# Plot the losses over epochs\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access training and validation losses from the history object\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# Print or plot the losses\n",
    "print(\"Training Losses:\", training_loss)\n",
    "print(\"Validation Losses:\", validation_loss)\n",
    "\n",
    "# Plot the losses over epochs\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d279b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
